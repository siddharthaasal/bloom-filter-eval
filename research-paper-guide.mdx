# Empirical Evaluation of Bloom Filter Variants

## Under Skewed, Adversarial, and Temporal Workloads

---

## 1. Research Objective

### Title

**_Empirical Evaluation of Bloom Filter Variants Under Skewed, Adversarial, and Temporal Workloads_**

### Core Research Question

How do different probabilistic membership filter implementations—**Standard Bloom**, **Counting Bloom**, **Scalable Bloom**, and **Cuckoo Filters**—behave under **realistic, non-uniform**, and **adversarial** workloads?

### Hypotheses

1. **Skewed Access (Zipfian)**  
   Filters with data locality (e.g., Cuckoo Filters or blocked Bloom variants) should benefit from skewed access patterns due to improved CPU cache utilization, whereas standard Bloom filters will exhibit little change.

2. **Adversarial Queries**  
   Query performance will degrade under adversarial workloads that target false positives, as these queries consistently trigger worst-case collision resolution paths.

3. **Temporal Dynamics**  
   Long-running, dynamically growing filters (Counting and Scalable Bloom Filters) may degrade over time due to fragmentation or layered growth, compared to fixed-capacity filters that rely on periodic rebuilds.

---

## 2. Methodology & Experimental Design

### A. Filter Implementations

_Independent Variable 1_

| Filter Type               | Implementation Strategy       | Key Characteristic       | Primary Trade-off         |
| ------------------------- | ----------------------------- | ------------------------ | ------------------------- |
| **Standard Bloom Filter** | `pybloom_live` (bitarray)     | Fixed-size, \(k\) hashes | No deletion               |
| **Counting Bloom Filter** | Custom (8-bit counters)       | Supports deletion        | \( \sim 8\times \) memory |
| **Scalable Bloom Filter** | `pybloom_live` (layered)      | Grows dynamically        | Slower queries            |
| **Cuckoo Filter**         | `cuckoofilter` (fingerprints) | Compact, deletable       | Variable insert cost      |

**Implementation Note**  
The Counting Bloom Filter is implemented using **8-bit counters** to guarantee correctness under heavy deletion workloads. While memory-expensive, this avoids overflow issues associated with 4-bit optimizations.

---

### B. Workload Models

_Independent Variable 2_

This study explicitly rejects the assumption that **uniform random access** sufficiently models real systems.

#### 1. Uniform (Baseline)

- Random integer keys
- Serves as a control group

---

#### 2. Zipfian (Skewed)

- **Motivation**: Real workloads follow power-law distributions (e.g., 80/20 rule)
- **Distribution**: Zipfian
- **Parameter**:  
  \[
  \alpha \in \{1.0, 1.2, 1.5\}
  \]
- Higher \( \alpha \) ⇒ greater skew
- **Expected Outcome**: Improved cache locality for hot keys, reflected in lower P99 latency

---

#### 3. Adversarial (Security-Oriented)

- **Motivation**: Probabilistic filters are commonly deployed in DDoS mitigation and abuse prevention systems
- **Attack Strategy**:
  - **Mining Phase**:  
    A shadow filter is trained offline
  - Keys are brute-forced until a large set of **false positives** is discovered
- **Query Workload**:
  - Dominated by mined false positives
  - Mixed with valid queries
- **Goal**:
  - Measure worst-case query behavior
  - Observe whether filters degrade catastrophically (e.g., repeated relocations in Cuckoo Filters or full-layer traversal in Scalable Bloom Filters)

---

#### 4. Temporal (Stability Over Time)

- **Motivation**: Real datasets evolve; hot keys shift
- **Design**:
  - Three sequential phases
  - Each phase activates a new working set
- **Metrics**:
  - Memory efficiency
  - False positive rate
  - Latency stability

##### Correctness Detail: Disjoint Negative Universe

Naïvely sampling random integers for false-positive measurement risks selecting keys that may be inserted in a future phase.

**Solution**:  
True negatives are drawn from a key range **strictly disjoint** from the entire universe of all phases.

This guarantees:

\[
\text{FPR} = \frac{\text{False Positives}}{\text{Total Disjoint Negatives}}
\]

is mathematically sound.

---

## 3. Evaluation Metrics

_Dependent Variables_

### 1. False Positive Rate (FPR)

- **Goal**: Accuracy under non-uniform workloads
- **Methodology**:
  - Query workload ≠ FPR measurement set
  - True negatives are guaranteed non-members
- **Formula**:
  \[
  \text{FPR} = \frac{\lvert \{k \mid k \in \text{Filter} \land k \in \text{TrueNegatives} \} \rvert}{\lvert \text{TrueNegatives} \rvert}
  \]
- **Target Configuration**: \( \approx 1\% \)

---

### 2. Latency (µs)

- **Insert Latency**: Cost of ingestion
- **Query Latency (Mean)**: Throughput
- **Query Latency (P99)**:
  - Primary systems metric
  - Indicates cache misses or worst-case collision behavior
- **Delete Latency**:
  - Measured for Counting Bloom and Cuckoo Filters

---

### 3. Memory Efficiency (Bits Per Key)

- **Bloom Variants**:
  - Calculated from allocated bitarray size
- **Cuckoo Filter**:
  - Uses **runtime introspection**
  - Capacity and fingerprint size queried directly from the library
  - Avoids reliance on purely theoretical formulas

**Observation**  
Cuckoo filters round table sizes to powers of two, resulting in step-function memory behavior—an important real-world nuance often omitted in analytical models.

---

## 4. Experimental Results Structure

_All plots are generated from CSV outputs in `src/results/`._

### Experiment 1: Impact of Skew

- **X-axis**: Zipf \( \alpha \)
- **Y-axis**: P99 Query Latency
- **Question**:
  - Do locality-aware filters benefit from skew?
  - Does Standard Bloom remain flat?

---

### Experiment 2: Adversarial Stress Test

- **Comparison**:
  - Uniform vs Adversarial queries
- **Metric**:
  - Query latency
- **Insight**:
  - False positives often require checking _all_ hash positions or buckets

---

### Experiment 3: Scalability Cost

- **Comparison**:
  - Standard Bloom vs Scalable Bloom
- **Focus**:
  - Latency penalty incurred for zero-configuration growth

---

## 5. Discussion & Practical Guidelines

### Filter Selection

- **Cuckoo Filter**
  - High read performance
  - Supports deletion
  - Best when memory is constrained
- **Counting Bloom Filter**
  - Simple semantics
  - Heavy deletions
  - Memory-rich environments
- **Scalable Bloom Filter**
  - Unknown dataset size
  - Acceptable latency overhead
- **Standard Bloom Filter**
  - Static datasets
  - Predictable performance

---

### Security Considerations

- Probabilistic filters are vulnerable to **algorithmic complexity attacks**
- Mitigations:
  - Hash seed rotation
  - Periodic filter rebuilds
  - Rate-limiting suspicious queries

---

## 6. Technical Nuances

### Cache-Proxy Interpretation

Direct cache-miss measurement is infeasible in Python.  
Instead, **P99 query latency** serves as a proxy:

- Stable P99 ⇒ cache-resident access
- Spikes ⇒ main memory fetch or collision amplification

---

### Implementation Boundaries

- Python introduces absolute overhead
- The evaluation focuses on **relative performance trends**, not nanosecond-level precision

---

### Adversarial Mining Cost

- Mining false positives becomes increasingly difficult as \( m/n \) grows
- Reinforces the importance of over-provisioning and hash randomization

---

## 7. Conclusion

This study demonstrates that probabilistic filters behave very differently under realistic workloads:

- Uniform benchmarks hide critical behaviors
- Skew reveals cache locality effects
- Adversarial inputs expose worst-case paths
- Temporal workloads highlight long-term stability trade-offs

**No single filter dominates**.  
Correct selection depends on workload shape, memory constraints, and security requirements.

---

## 8. Next Steps

1. Increase `NUM_KEYS` to \(10^5\)–\(10^6\) and run overnight benchmarks
2. Generate plots using `matplotlib`
3. Draft the **System Model** section while experiments execute
